---
title: "Prepare data for Jenn and Mathilde Manual Acoustic Analysis"
output: html_document
date: "2022-11-21"
---

```{r setup, echo = F}

knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(tidy = "styler")
 

getwd()

library(data.table)
library(tidyverse)
library(beepr)
library(lubridate)
library(purrr)
#renv::install("rstudio/renv")
library(renv)
library(stringr)
```

# Extract raw bat acoustic data for manual acoustic analysis for Jenn Fairchild's manual acoustic analysis
1.a - Read id.csv files from all WAV folder directories of the bat acoustic data from the Follo Forest 2022 and 2022 field seasons 
1.b - Combine those id.csv's into one master csv file
2.a - Subset to only include files that correspond to AUTO.ID.s of PIPY, PIPI, PINA, NoID, NYNO (Jenn) -J1 
2.b - Subset to only include Myotis and Plecotus species as well as BABA (Mathilde) - M1 
3.a - Subset J1 to only include data between May 15 and 27 June for both seasons  - J2 
3.b - Subset M1 to only include the data from 2022 (whole season) - M2
4.a - Copy files that match J2 into the external hard disk 
4.b - Copy files that match M2 into the Project Largefile. 

## 2022 FIRST
Step 1 - read the csv files of all bat acoustic data for both Follo Forest seasons and combine them 
```{r}

## 2022 
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022"))) 
#only 2022 data)
getwd()
# "////largefile.nmbu.no/Project/FolloForest2022/FolloForest2022"

# Specify directories
# 2


# folders where csv files are all in for each site
inputFF01_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF01" 

inputFF02_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF02" 

inputFF03_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF03" 

inputFF04_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF04" 

inputFF05_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF05" 

inputFF06_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF06" 

inputFF07_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF07" 

inputFF08_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF08" 

inputFF09_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF09" 

inputFF10_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF10" 

inputFF11_22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF11"


output22 <-"//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/Extraction" # where you want to save your data
name   <-"FF22AutoClass.csv"



#To set the path to your csv files
#To grab and list all your csv files
#my_files <- list.files(path=path, pattern="*.txt")

# It can take a while to load each set of csv files so I find the beepr package helpful here... 

FF1<- list.files(path=inputFF01_22, pattern="id.csv", recursive = TRUE)
beep() 

FF2<- list.files(path=inputFF02_22, pattern="id.csv", recursive = TRUE)
beep() 

FF3<- list.files(path=inputFF03_22, pattern="id.csv", recursive = TRUE)
beep()

FF4<- list.files(path=inputFF04_22, pattern="id.csv", recursive = TRUE)
beep()

FF5<- list.files(path=inputFF05_22, pattern="id.csv", recursive = TRUE)
beep()

FF6<- list.files(path=inputFF06_22, pattern="id.csv", recursive = TRUE)
beep()

FF7<- list.files(path=inputFF07_22, pattern="id.csv", recursive = TRUE)
beep()

FF8<- list.files(path=inputFF08_22, pattern="id.csv", recursive = TRUE)
beep()

FF9<- list.files(path=inputFF09_22, pattern="id.csv", recursive = TRUE)
beep()

FF10<- list.files(path=inputFF10_22, pattern="id.csv", recursive = TRUE)
beep()

FF11<- list.files(path=inputFF11_22, pattern="id.csv", recursive = TRUE)
beep()



getwd()
# "\\\\largefile.nmbu.no/Project/FolloForest2022/FolloForest2022"

FF1
# Slight gap between these so I need to manually reset the root directory for every site:( )


# #To read all your csv files and create a list with all these elements

## FF01 
knitr::opts_chunk$set(
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF01")))
getwd()

FF01_data <- lapply(FF1, read.csv)

## FF02
knitr::opts_chunk$set(
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF02")))
getwd()

 FF02_data <- lapply(FF2, read.csv)

 ## FF03 
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF03")))
getwd()

 FF03_data <- lapply(FF3, read.csv)

 ## FF04
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF04")))
getwd()

 FF04_data <- lapply(FF4, read.csv)
 
## FF05
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF05")))
getwd()

 FF05_data <- lapply(FF5, read.csv)
 
## FF06
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF06")))
getwd()

 FF06_data <- lapply(FF6, read.csv)
 
## FF07
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF07")))
getwd()

 FF07_data <- lapply(FF7, read.csv)

 ## FF08
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF08")))
getwd() 

  FF08_data <- lapply(FF8, read.csv)

 ## FF09
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF09")))
getwd() 
 
  FF09_data <- lapply(FF9, read.csv)

 ## FF10
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF10")))
getwd() 

   FF10_data <- lapply(FF10, read.csv)

  ## FF11
knitr::opts_chunk$set(
    # This should allow Rmarkdown to locate the data
    root.dir = setwd(rprojroot::find_rstudio_root_file( "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF11")))
getwd()   
   
 FF11_data <- lapply(FF11, read.csv)

# 
  
#To add the name of each csv in the list
names(FF01_data) <- gsub("//.csv$", "", FF1)
names(FF02_data) <- gsub("//.csv$", "", FF2)
names(FF03_data) <- gsub("//.csv$", "", FF3)
names(FF04_data) <- gsub("//.csv$", "", FF4)
names(FF05_data) <- gsub("//.csv$", "", FF5)
names(FF06_data) <- gsub("//.csv$", "", FF6)
names(FF07_data) <- gsub("//.csv$", "", FF7)
names(FF08_data) <- gsub("//.csv$", "", FF8)
names(FF09_data) <- gsub("//.csv$", "", FF9)
names(FF10_data) <- gsub("//.csv$", "", FF10)
names(FF11_data) <- gsub("//.csv$", "", FF11)



#To create one single dataframe with all single dataframes
big_FF01<- rbindlist(FF01_data, fill = TRUE)
big_FF02<- rbindlist(FF02_data, fill = TRUE)
big_FF03<- rbindlist(FF03_data, fill = TRUE)
big_FF04<- rbindlist(FF04_data, fill = TRUE)
big_FF05<- rbindlist(FF05_data, fill = TRUE)
big_FF06<- rbindlist(FF06_data, fill = TRUE)
big_FF07<- rbindlist(FF07_data, fill = TRUE)
big_FF08<- rbindlist(FF08_data, fill = TRUE)
big_FF09<- rbindlist(FF09_data, fill = TRUE)
big_FF10<- rbindlist(FF10_data, fill = TRUE)
big_FF11<- rbindlist(FF11_data, fill = TRUE)


alist = list(big_FF01, big_FF02, big_FF03, big_FF04, big_FF05, big_FF06, big_FF07, big_FF08, big_FF09, big_FF10, big_FF11)

big_data <- rbindlist(alist, fill=TRUE)


# Explore where the NAs are coming from... 

big_data$AUTO.ID. <- as.factor(big_data$AUTO.ID.)
summary(big_data$AUTO.ID.)

# BARBAR EPTNIL EPTSER MYOALC MYOBEC MYOBRA MYODAS MYODAU MYOMYO MYOMYS MYONAT NYCLEI NYCNOC 
#    631  45127   2012    115    217  11609   4262  12708    229   9830    367    833   4868 
#   NoID  Noise PIPNAT PIPPIP PIPPYG PLEAUR PLEAUS VESMUR   NA's 
#  60138 302293    730   8097  27680   4106    384    180   1323 

summary(big_data$AUTO.ID)
summary(FF07_data)
big_FF07$AUTO.ID. <- as.factor(big_FF07$AUTO.ID.)
summary(big_FF07$AUTO.ID.) # 1323 NAs from FF07-IB/WAV/WAV_FF07-IB_05.07.2022/id.csv.... 

# I am going to try deleting data from this selection and then re-merging it... 

big_data1 <- big_data %>% filter(!str_detect( OUTDIR, 'FF07-IB_05.07.2022'))
dim(big_data)
# 497739     45
dim(big_data1)
# 496416     45

# 497739 - 496416 = 1323 (good)

trythis <- read.csv("//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/FF07/FF07-IB/WAV/WAV_FF07-IB_05.07.2022/id.csv") # looks much better! 

# the problem is that there is not an "AUTO.ID." column in this id.csv, only an "AUTO.ID"
# Easy enough to fix. 

trythis$AUTO.ID. <- trythis$AUTO.ID

big_data2 <- full_join(trythis, big_data1) ## duplicates!! 

big_data2$AUTO.ID. <- as.factor(big_data2$AUTO.ID.)
summary(big_data2$AUTO.ID.) # No more NAs! 

setwd("//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/Extraction")

getwd()

#write.csv(big_data2, "2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_unedited.csv")
beep()

# In any case, it should be safe to remove these NAs. 
levels(big_data2$AUTO.ID.)
dim(big_data2)

# 497739     45

# Remove the 261602 NOISE files as well. 

big_data3 <- big_data2 %>% filter(AUTO.ID. != "Noise") %>%  droplevels() 
summary(big_data3$AUTO.ID.)
dim(big_data3)
# 194502     45

#write.csv(big_data3, "2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise.csv")
beep() 

```

# Step 2 - 2022
## 2022 data for Mathilde 
Mathilde probably won't use the 2022 dataset so I do not need to worry about this for now. 
```{r}
# # Grab all NoID, Plecotus species, Myotis species and Barbastelle observations. 
# 
levels(big_data3$AUTO.ID.)
M1 <- big_data2 %>% filter(AUTO.ID. %in% c("BARBAR", "MYOALC", "MYOBEC", "MYOBRA", "MYODAS", "MYODAU", "MYOMYO", "MYOMYS", "MYONAT", "PLEAUR", "PLEAUS", "NoID")) %>% droplevels()
 dim(M1) # 104884     45
 summary(M1)
 summary(M1$AUTO.ID.)
# BARBAR MYOALC MYOBEC MYOBRA MYODAS MYODAU MYOMYO MYOMYS MYONAT   NoID PLEAUR PLEAUS 
#    636    115    218  11702   4262  12722    229   9846    367  60297   4106    384 
# 
#write.csv(M1, "2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise_SRE_NoID_Only.csv")
#M1 <- X2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise_SRE_NoID_Only 
 
M1$AUTO.ID. <- as.factor(M1$AUTO.ID.) 
# 
# ## EVENTUALLY ###
#  
# #Copy these files to a separate location.... 
```

# Step 3 - 2022 
## 2022 data for Jenn 

```{r}

J1 <- big_data3 
J1$date <- as.Date(J1$DATE)

# Filter to only include dates from 15.05 to 27.06 (least amount of equipment failures) 
# subset(temp, date> "2014-12-03" & date < "2014-12-05")
J1. <- subset(J1, date > "2022-05-14" & date < "2022-06-28")
dim(J1.) # [1] 65477    46
summary(J1.)
summary(J1.$AUTO.ID.)

# BARBAR EPTNIL EPTSER MYOALC MYOBEC MYOBRA MYODAS MYODAU MYOMYO MYOMYS MYONAT NYCLEI NYCNOC   NoID PIPNAT 
#    330  16919    730     44     54   3509    854   3359     23   3280    160    214   1145  20303   1455 
# PIPPIP PIPPYG PLEAUR PLEAUS VESMUR 
#    833  14737    168     35     57 

#write.csv(J1., "2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise_15-05_to_27_06.csv")
# Filter to only include MRE, NoID and Noctule species 


J2 <- J1. %>% filter(AUTO.ID. %in% c("NYCLEI", "NYCNOC", "NoID", "PIPNAT", "PIPPIP", "PIPPYG")) %>% droplevels() 

dim(J2) # [1] 38687    46
summary(J2$AUTO.ID.)
# NYCLEI NYCNOC   NoID PIPNAT PIPPIP PIPPYG 
#    214   1145  20303   1455    833  14737 

#write.csv(J2, "2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise_MREandNoIDandNyctalus_15-05_to_27_06.csv")

J3 <- J2 %>% select(2:46)
#write.csv(J3, "id_2022_AutomaticallyProcessed_BatAcousticData_allsitescombined_dropNA_dropNoise_MREandNoIDandNyctalus_15-05_to_27_06.csv")
```


# Copy the 2022 filepaths into a new directory 

```{r}
getwd()
# This next command will take forever to run - do not rerun it on accident! 

# Select all files with their complete file paths 
# mass_inventory <- list.files("//largefile.nmbu.no/Project/FolloForest2021/FolloForest2022/Acoustics/", pattern = "_000.wav", recursive = TRUE, all.files = FALSE, full.names = TRUE, ignore.case = FALSE)
#  beep()
# 
#write.csv(mass_inventory, "complete file path, all bat acoustic data Follo Forest2022.csv")

mass_inventory_df <- as.data.frame(mass_inventory)
head(mass_inventory_df) # 497758 obs
# Exaple of one observation: 
#//largefile.nmbu.no/Project/FolloForest2021/FolloForest2022/Acoustics//FF01/FF01-CB/WAV/WAV_FF01-CB_05.07.2022/Data/S4U12331_20220607_220237_000.wav

str(mass_inventory_df) # need to drop index column and rename mass_inventory column 
mass_inventory_df <- mass_inventory_df  %>% rename(fullpath = mass_inventory) 

mass_inventory_df$map <- mass_inventory_df$fullpath# make copy of the complete file paths column 
mass_inventory_df1 <- mass_inventory_df %>% filter(!str_detect(fullpath, "NOISE")) 
# No noise to remove 


mass_inventory_df2 <- mass_inventory_df1 %>% mutate(map1 = str_remove(map, "//largefile.nmbu.no/Project/FolloForest2021/FolloForest2022/Acoustics//"))  
head(mass_inventory_df2$map1)

# Parse out the different directories
cols <- c("Site", "Plot", "WAV", "Collection", "Data", "Data1", "file.name")
mass_inventory_df3 <- mass_inventory_df2 %>% tidyr::separate(col = map1, 
                                                             sep = "/",
                                                             into = cols, 
                                                             remove = FALSE) 
# parse out the file paths to just get the file names
# For some directories there were two "Data" folders (Data/Data) so I will need to recreate a complete file list from the two columns... 
summary(mass_inventory_df3)
# create a list now of only file names. 
filelist1 <- mass_inventory_df3 %>% select(Data1) 
# this column contains either "Data" or a file name - remove any rows that are 'Data'
filelist1 <- subset(filelist1, Data1 != "Data") %>% rename(file.name = Data1) # 494315 obs 
filelist1_list <- list(filelist1) # now a list of file names 

# This column contains either file names or NA, remove NAs 
filelist2 <- mass_inventory_df3 %>% select(file.name) %>% drop_na(file.name) # 3443 obs
filelist2_list <- list(filelist2) # second list of file names 

summary(filelist1)
summary(filelist2)  

# 494315 + 3443 = 497758 ## This is should be length of the final file list. 
filelist3 <- full_join(filelist1, filelist2)# 497758 obs, perfect!

#Now add this back as a column to the earlier dataset. 
mass_inventory_df4 <- mass_inventory_df3
mass_inventory_df4$filename <- filelist3$file.name 
summary(mass_inventory_df4)

#write.csv(mass_inventory_df4, "complete filepaths FolloForest2022 parsed.csv")

inventory <- mass_inventory_df4 %>% 
  select(map, Site, Plot, Collection, filename) %>% 
  mutate(Site = as.factor(Site), 
         Plot = as.factor(Plot), 
         Collection = as.factor(Collection),
         file.name = as.factor(filename)) %>% distinct()

## CHECK FOR DUPLICATES!

# In the first week of Jan 2023 I found three folders with duplicates: 


# n_occur <- data.frame(table(inventory$file.name))
# test <- n_occur[n_occur$Freq > 1,]
# # S4U11194 and S4U12480 duplicated...
# 
# fishing <- inventory %>% filter(str_detect(file.name,"S4U11994")) 
# summary(fishing)
# 
# fish.test <- subset(inventory,duplicated(file.name)) %>% droplevels()
# summary(fish.test)
# 
# fish.test1 <- fish.test %>% filter(Collection == "WAV_FF06-OB_A_20.09.2022")
# 
# summary(inventory)# 497758 

# summary(fish.test$Collection)
# WAV_FF06-OB_A_20.09.2022   WAV_FF08-OB_08.06.2022 WAV_FF08-OB_B_30.08.2022 
#                       13                     4295                    26525 

# For the folders in FF08, this was a simple issue of having accidentally processed the same raw data twice into the wrong folders. I deleted the duplicates and processed the appropriate raw data. 

# In the FF06 folder, something stranger had happen where 13 somewhat random (not entirely sequential) files were copied into the wrong folder (FF6OB_30.08.2022). These files were not found in the id.csv file for that folder. I moved them into the FolloForest2022 Troubleshooting folder with a brief README file describing them. 

```

# Extract Mathilde's data and copy to another folder 
```{r}
#create a column that is easy to index with J2
M1_map <- M1 %>% select(OUT.FILE.FS) %>% rename(filename = OUT.FILE.FS)
M1_map1 <- M1_map %>% distinct() 
M1_map_list <- list(M1_map$filename) # 104884 files
M1_map_list1 <- list(M1_map1$filename) # 101189 files - duplicates removed
# subset the masss inventory to only include files that match what Mathilde needs. 
str(inventory)
str(M1_map1)
MFilePaths <- merge(M1_map1, inventory, all.x = TRUE) %>% distinct()

summary(MFilePaths) #104877 observations 

test <- as.data.frame(duplicated(M1_map1))
dups <- test %>% filter(duplicated(M1_map1) == "TRUE") # 3695 duplicates... 
# 104884 - 104877 = 7 ... there are 7 passes that do not match... I may just have to live with that for now. 

# 38687 - 36162 = 2525 
# 2525 files missing for some reason.... 
# check for duplicates in the J2_map object
# test <- duplicated(M1_map)
# J2_map$filename[duplicated(J2_map$filename)] 
# summary(test) # 2524 - looks like they are all duplicate files... 
# test to see if removing these also removes the NAs in the OUT FILE ZS issue... 

# J2 has 38687 observations
# test1 <- J2 %>% distinct(OUT.FILE.FS) 
# test1 has 36163 observations
# 38687-36163 = 2524 
# There were a series of input directories assosciated with these NAs:
# FF6-OB_17.08.2022
# FF6-CB_17.08.2022
# FF6-IB_30.07.2022
# FF7-OB_13.07.2022
# FF7-IB_28.06.2022
# FF7-CB_28.06.2022
# FF6-OB_30.05.2022

# They all DO HAVE .000.wav files there, but for some reason a proportion of them are not recorded in the id.csvs assosciated with these data recoveries... for now I will have to ignore them but may extract entire datasets from these folders later if it looks like these 2000 ish observations are not just strange duplicates. 

my_files <- as.list(JennFilePaths$mass_inventory)
my_files_list <- unlist(my_files)# 36162 files 
head(my_files)
View(mass_inventory)

# file.copy(from = my_files_list, 
#           to = "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/ForJenn")

```


# extract Jenn's data 
```{r}
#create a column that is easy to index with J2
J2_map <- J2 %>% select(OUT.FILE.FS) %>% rename(filename = OUT.FILE.FS)
J2_map_list <- list(J2_map$filename) # 38687 files

# subset the masss inventory to only include files that match what Jenn needs. 
str(mass_inventory_df4)
str(J2_map)
JennFilePaths <- inner_join(mass_inventory_df4, J2_map, by = "filename") 


# 38687 - 36162 = 2525 
# 2525 files missing for some reason.... 
# check for duplicates in the J2_map object
test <- duplicated(J2_map)
J2_map$filename[duplicated(J2_map$filename)] 
summary(test) # 2524 - looks like they are all duplicate files... 
# test to see if removing these also removes the NAs in the OUT FILE ZS issue... 

# J2 has 38687 observations
test1 <- J2 %>% distinct(OUT.FILE.FS) 
# test1 has 36163 observations
# 38687-36163 = 2524 
# There were a series of input directories assosciated with these NAs:
# FF6-OB_17.08.2022
# FF6-CB_17.08.2022
# FF6-IB_30.07.2022
# FF7-OB_13.07.2022
# FF7-IB_28.06.2022
# FF7-CB_28.06.2022
# FF6-OB_30.05.2022

# They all DO HAVE .000.wav files there, but for some reason a proportion of them are not recorded in the id.csvs assosciated with these data recoveries... for now I will have to ignore them but may extract entire datasets from these folders later if it looks like these 2000 ish observations are not just strange duplicates. 

my_files <- as.list(JennFilePaths$mass_inventory)
my_files_list <- unlist(my_files)# 36162 files 
head(my_files)
View(mass_inventory)

file.copy(from = my_files_list, 
          to = "//largefile.nmbu.no/Project/FolloForest2022/FolloForest2022/Acoustics/ForJenn")

```

